{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading LibriSpeech dataset...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 50\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# Execution\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 50\u001b[0m     \u001b[43mdownload_librispeech\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m prepare_dataset()\n\u001b[0;32m     52\u001b[0m     processed_data \u001b[38;5;241m=\u001b[39m preprocess_data(dataset)\n",
      "Cell \u001b[1;32mIn[1], line 16\u001b[0m, in \u001b[0;36mdownload_librispeech\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading LibriSpeech dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m os\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m\"\u001b[39m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 16\u001b[0m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting LibriSpeech dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tarfile\u001b[38;5;241m.\u001b[39mopen(target_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr:gz\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m tar:\n",
      "File \u001b[1;32mc:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\urllib\\request.py:268\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reporthook:\n\u001b[0;32m    266\u001b[0m     reporthook(blocknum, bs, size)\n\u001b[1;32m--> 268\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m block \u001b[38;5;241m:=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    269\u001b[0m     read \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(block)\n\u001b[0;32m    270\u001b[0m     tfp\u001b[38;5;241m.\u001b[39mwrite(block)\n",
      "File \u001b[1;32mc:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[0;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[1;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[0;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mc:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1253\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1249\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1250\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1251\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1252\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1105\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1103\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1106\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1107\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torchaudio\n",
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "from torchaudio.datasets import LIBRISPEECH\n",
    "\n",
    "# Step 1: Download the dataset\n",
    "def download_librispeech():\n",
    "    url = \"https://www.openslr.org/resources/12/train-clean-100.tar.gz\"\n",
    "    target_path = \"./data/librispeech.tar.gz\"\n",
    "    extract_path = \"./data/librispeech\"\n",
    "\n",
    "    if not os.path.exists(extract_path):\n",
    "        print(\"Downloading LibriSpeech dataset...\")\n",
    "        os.makedirs(\"./data\", exist_ok=True)\n",
    "        urllib.request.urlretrieve(url, target_path)\n",
    "        print(\"Extracting LibriSpeech dataset...\")\n",
    "        with tarfile.open(target_path, 'r:gz') as tar:\n",
    "            tar.extractall(path=\"./data\")\n",
    "        print(\"Dataset ready.\")\n",
    "    else:\n",
    "        print(\"Dataset already downloaded.\")\n",
    "\n",
    "# Step 2: Load the dataset\n",
    "def prepare_dataset():\n",
    "    dataset_path = \"./data/LibriSpeech/train-clean-100\"\n",
    "    if not os.path.exists(dataset_path):\n",
    "        raise FileNotFoundError(\"Dataset not found. Run download_librispeech() first.\")\n",
    "    \n",
    "    print(\"Loading dataset...\")\n",
    "    dataset = LIBRISPEECH(\"./data\", url=\"train-clean-100\", download=False)\n",
    "    print(f\"Loaded {len(dataset)} samples.\")\n",
    "    return dataset\n",
    "\n",
    "# Step 3: Preprocess the data\n",
    "def preprocess_data(dataset, max_samples=100):\n",
    "    processed_data = []\n",
    "    print(f\"Processing first {max_samples} samples...\")\n",
    "    for i, (waveform, sample_rate, _, _, _, _) in enumerate(dataset):\n",
    "        if i >= max_samples:\n",
    "            break\n",
    "        # Convert waveform to spectrogram\n",
    "        spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate)(waveform)\n",
    "        processed_data.append((spectrogram, sample_rate))\n",
    "    print(\"Data preprocessing complete.\")\n",
    "    return processed_data\n",
    "\n",
    "# Execution\n",
    "if __name__ == \"__main__\":\n",
    "    download_librispeech()\n",
    "    dataset = prepare_dataset()\n",
    "    processed_data = preprocess_data(dataset)\n",
    "    print(f\"Processed {len(processed_data)} samples into spectrograms.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading SPEECHCOMMANDS dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.26G/2.26G [01:57<00:00, 20.7MB/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data\\\\SpeechCommands\\\\speech_commands_v0.02\\\\training_list.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Execution\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Load and preprocess a small subset\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     processed_data \u001b[38;5;241m=\u001b[39m preprocess_data(dataset, max_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(processed_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples into spectrograms.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 20\u001b[0m, in \u001b[0;36mprepare_dataset\u001b[1;34m(subset)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_dataset\u001b[39m(subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading SPEECHCOMMANDS dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mSubsetSC\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m, in \u001b[0;36mSubsetSC.__init__\u001b[1;34m(self, root, subset)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(root, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subset:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_walker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 14\u001b[0m, in \u001b[0;36mSubsetSC._load_list\u001b[1;34m(self, subset)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, subset):\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msubset\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_list.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path, line\u001b[38;5;241m.\u001b[39mstrip()) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f]\n",
      "File \u001b[1;32mc:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data\\\\SpeechCommands\\\\speech_commands_v0.02\\\\training_list.txt'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.datasets import SPEECHCOMMANDS\n",
    "\n",
    "# Dataset preparation\n",
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, root, subset: str = None):\n",
    "        super().__init__(root, download=True)\n",
    "        if subset:\n",
    "            self._walker = self._load_list(subset)\n",
    "\n",
    "    def _load_list(self, subset):\n",
    "        with open(os.path.join(self._path, f\"{subset}_list.txt\")) as f:\n",
    "            return [os.path.join(self._path, line.strip()) for line in f]\n",
    "\n",
    "# Step 1: Load a small dataset\n",
    "def prepare_dataset(subset=\"training\"):\n",
    "    print(\"Loading SPEECHCOMMANDS dataset...\")\n",
    "    dataset = SubsetSC(\"./data\", subset=subset)\n",
    "    print(f\"Loaded {len(dataset)} samples from {subset} set.\")\n",
    "    return dataset\n",
    "\n",
    "# Step 2: Preprocess data to extract spectrograms\n",
    "def preprocess_data(dataset, max_samples=100):\n",
    "    processed_data = []\n",
    "    print(f\"Processing first {max_samples} samples...\")\n",
    "    for i, (waveform, sample_rate, label, *_rest) in enumerate(dataset):\n",
    "        if i >= max_samples:\n",
    "            break\n",
    "        # Convert waveform to Mel spectrogram\n",
    "        spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate)(waveform)\n",
    "        processed_data.append((spectrogram, label))\n",
    "    print(\"Data preprocessing complete.\")\n",
    "    return processed_data\n",
    "\n",
    "# Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess a small subset\n",
    "    dataset = prepare_dataset(subset=\"training\")\n",
    "    processed_data = preprocess_data(dataset, max_samples=50)\n",
    "    print(f\"Processed {len(processed_data)} samples into spectrograms.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 50 samples...\n",
      "Data preprocessing complete.\n",
      "Processed 50 samples into spectrograms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Custom dataset to load audio files directly\n",
    "class SpeechCommandsDataset(Dataset):\n",
    "    def __init__(self, root_dir, max_samples=50):\n",
    "        self.root_dir = root_dir\n",
    "        self.max_samples = max_samples\n",
    "        self.file_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Load all file paths and labels\n",
    "        for label in os.listdir(root_dir):\n",
    "            label_path = os.path.join(root_dir, label)\n",
    "            if os.path.isdir(label_path):\n",
    "                files = os.listdir(label_path)\n",
    "                for file in files:\n",
    "                    if file.endswith('.wav'):\n",
    "                        self.file_paths.append(os.path.join(label_path, file))\n",
    "                        self.labels.append(label)\n",
    "                        # Stop if max samples reached\n",
    "                        if len(self.file_paths) >= self.max_samples:\n",
    "                            break\n",
    "            if len(self.file_paths) >= self.max_samples:\n",
    "                break\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        waveform, sample_rate = torchaudio.load(file_path)\n",
    "        return waveform, sample_rate, label\n",
    "\n",
    "# Initialize the dataset\n",
    "dataset_root = \"data/SpeechCommands/speech_commands_v0.02\"  # Path to your data\n",
    "dataset = SpeechCommandsDataset(dataset_root, max_samples=50)\n",
    "\n",
    "# Process data into spectrograms\n",
    "def preprocess_data(dataset):\n",
    "    processed_data = []\n",
    "    print(f\"Processing {len(dataset)} samples...\")\n",
    "    for waveform, sample_rate, label in dataset:\n",
    "        # Convert waveform to Mel spectrogram\n",
    "        spectrogram = torchaudio.transforms.MelSpectrogram(sample_rate=sample_rate)(waveform)\n",
    "        processed_data.append((spectrogram, label))\n",
    "    print(\"Data preprocessing complete.\")\n",
    "    return processed_data\n",
    "\n",
    "# Execution\n",
    "processed_data = preprocess_data(dataset)\n",
    "print(f\"Processed {len(processed_data)} samples into spectrograms.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Epoch 1/10, Train Loss: 4.6135, Val Loss: 3.5745\n",
      "Epoch 2/10, Train Loss: 3.4075, Val Loss: 2.2307\n",
      "Epoch 3/10, Train Loss: 2.0045, Val Loss: 1.0715\n",
      "Epoch 4/10, Train Loss: 1.0954, Val Loss: 0.5076\n",
      "Epoch 5/10, Train Loss: 0.5408, Val Loss: 0.2921\n",
      "Epoch 6/10, Train Loss: 0.3267, Val Loss: 0.1778\n",
      "Epoch 7/10, Train Loss: 0.1432, Val Loss: 0.0962\n",
      "Epoch 8/10, Train Loss: 0.0581, Val Loss: 0.0441\n",
      "Epoch 9/10, Train Loss: 0.0294, Val Loss: 0.0182\n",
      "Epoch 10/10, Train Loss: 0.0257, Val Loss: 0.0076\n",
      "Model saved to voice_profile_model.pth\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Dataset class\n",
    "class VoiceProfileDataset(Dataset):\n",
    "    def __init__(self, data, label_mapping):\n",
    "        self.data = data\n",
    "        self.label_mapping = label_mapping  # Map string labels to integers\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spectrogram, label = self.data[idx]\n",
    "        label = self.label_mapping[label]  # Convert string label to integer\n",
    "        return spectrogram, label\n",
    "\n",
    "# Padding function for variable-length spectrograms\n",
    "def collate_fn(batch):\n",
    "    spectrograms = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "\n",
    "    # Find max width of spectrograms in the batch\n",
    "    max_width = max([spec.shape[-1] for spec in spectrograms])\n",
    "\n",
    "    # Pad spectrograms to the same width\n",
    "    padded_spectrograms = []\n",
    "    for spec in spectrograms:\n",
    "        padding = max_width - spec.shape[-1]\n",
    "        padded_spec = torch.nn.functional.pad(spec, (0, padding))  # Pad width dimension\n",
    "        padded_spectrograms.append(padded_spec)\n",
    "\n",
    "    # Stack into tensor with shape (batch_size, 1, height, width)\n",
    "    spectrograms_tensor = torch.stack(padded_spectrograms)  # No unsqueeze(1)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "\n",
    "    return spectrograms_tensor, labels_tensor\n",
    "\n",
    "# Simple CNN model for feature extraction\n",
    "class VoiceProfileModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VoiceProfileModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Placeholder for the size after convolution and pooling\n",
    "        self.flatten_size = None\n",
    "        self.fc1 = None\n",
    "        self.fc2 = nn.Linear(256, 128)  # Embedding for the voice profile\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "\n",
    "        # Dynamically set the input size for fc1 during the first forward pass\n",
    "        if self.flatten_size is None:\n",
    "            self.flatten_size = x.view(x.size(0), -1).size(1)\n",
    "            self.fc1 = nn.Linear(self.flatten_size, 256).to(x.device)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.float().to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.float().to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "# Save and load functions for the model\n",
    "def save_model(model, path=\"voice_profile_model.pth\"):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(model, path=\"voice_profile_model.pth\"):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    return model\n",
    "\n",
    "# Plot training and validation losses\n",
    "def plot_losses(train_losses, val_losses):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Prepare data and dataloaders\n",
    "def prepare_dataloader(processed_data, batch_size=16):\n",
    "    # Create label mapping (string -> integer)\n",
    "    unique_labels = sorted(set(label for _, label in processed_data))\n",
    "    label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "    dataset = VoiceProfileDataset(processed_data, label_mapping)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return train_loader, val_loader, label_mapping\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming processed_data is already prepared and contains (spectrogram, label) tuples\n",
    "    # Example: [(spectrogram1, \"label1\"), (spectrogram2, \"label2\"), ...]\n",
    "\n",
    "    train_loader, val_loader, label_mapping = prepare_dataloader(processed_data)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = VoiceProfileModel().to(device)\n",
    "\n",
    "    # Train the model\n",
    "    train_losses, val_losses = train_model(model, train_loader, val_loader, epochs=10, lr=0.001)\n",
    "\n",
    "    # Save the trained model\n",
    "    save_model(model)\n",
    "\n",
    "    # Plot the training and validation losses\n",
    "    plot_losses(train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [16, 1, 1, 128, 81]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 185\u001b[0m\n\u001b[0;32m    182\u001b[0m model \u001b[38;5;241m=\u001b[39m VoiceProfileModel()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m train_losses, val_losses, val_accuracies \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# Save the trained model\u001b[39;00m\n\u001b[0;32m    188\u001b[0m save_model(model)\n",
      "Cell \u001b[1;32mIn[13], line 92\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, epochs, lr)\u001b[0m\n\u001b[0;32m     90\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     91\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 92\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     94\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[13], line 63\u001b[0m, in \u001b[0;36mVoiceProfileModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 63\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     64\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[0;32m     65\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(torch\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)))\n",
      "File \u001b[1;32mc:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:458\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    457\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\msigm\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:454\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    452\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    453\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 3D (unbatched) or 4D (batched) input to conv2d, but got input of size: [16, 1, 1, 128, 81]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, Dataset\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Dataset class\n",
    "class VoiceProfileDataset(Dataset):\n",
    "    def __init__(self, data, label_mapping):\n",
    "        self.data = data\n",
    "        self.label_mapping = label_mapping  # Map string labels to integers\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spectrogram, label = self.data[idx]\n",
    "        label = self.label_mapping[label]  # Convert string label to integer\n",
    "        return spectrogram, label\n",
    "\n",
    "# Padding function for variable-length spectrograms\n",
    "\n",
    "def collate_fn(batch):\n",
    "    spectrograms = [item[0] for item in batch]\n",
    "    labels = [item[1] for item in batch]\n",
    "\n",
    "    # Find max width of spectrograms in the batch\n",
    "    max_width = max([spec.shape[-1] for spec in spectrograms])\n",
    "\n",
    "    # Pad spectrograms to the same width\n",
    "    padded_spectrograms = []\n",
    "    for spec in spectrograms:\n",
    "        padding = max_width - spec.shape[-1]\n",
    "        padded_spec = torch.nn.functional.pad(spec, (0, padding))  # Pad width dimension\n",
    "        padded_spectrograms.append(padded_spec)\n",
    "\n",
    "    # Stack into tensor with shape (batch_size, 1, height, width)\n",
    "    spectrograms_tensor = torch.stack(padded_spectrograms)  # Usunięto unsqueeze(1)\n",
    "    labels_tensor = torch.tensor(labels)\n",
    "\n",
    "    return spectrograms_tensor, labels_tensor\n",
    "\n",
    "\n",
    "# Simple CNN model for feature extraction\n",
    "class VoiceProfileModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VoiceProfileModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Placeholder for the size after convolution and pooling\n",
    "        self.flatten_size = None\n",
    "        self.fc1 = None\n",
    "        self.fc2 = nn.Linear(256, 128)  # Embedding for the voice profile\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        x = self.pool(torch.relu(self.conv3(x)))\n",
    "\n",
    "        # Dynamically set the input size for fc1 during the first forward pass\n",
    "        if self.flatten_size is None:\n",
    "            self.flatten_size = x.view(x.size(0), -1).size(1)\n",
    "            self.fc1 = nn.Linear(self.flatten_size, 256).to(x.device)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(torch.relu(self.fc1(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Train the model and compute accuracy\n",
    "def train_model(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    train_losses, val_losses = [], []\n",
    "    val_accuracies = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.float().to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.float().to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accuracy = correct / total\n",
    "        val_accuracies.append(val_accuracy)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Val Loss: {val_losses[-1]:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    return train_losses, val_losses, val_accuracies\n",
    "\n",
    "# Save and load functions for the model\n",
    "def save_model(model, path=\"voice_profile_model.pth\"):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model saved to {path}\")\n",
    "\n",
    "def load_model(model, path=\"voice_profile_model.pth\"):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded from {path}\")\n",
    "    return model\n",
    "\n",
    "# Plot training and validation losses and accuracy\n",
    "def plot_metrics(train_losses, val_losses, val_accuracies):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Loss plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Prepare data and dataloaders\n",
    "def prepare_dataloader(processed_data, batch_size=16):\n",
    "    # Create label mapping (string -> integer)\n",
    "    unique_labels = sorted(set(label for _, label in processed_data))\n",
    "    label_mapping = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "\n",
    "    dataset = VoiceProfileDataset(processed_data, label_mapping)\n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    return train_loader, val_loader, label_mapping\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming processed_data is already prepared and contains (spectrogram, label) tuples\n",
    "    train_loader, val_loader, label_mapping = prepare_dataloader(processed_data)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = VoiceProfileModel().to(device)\n",
    "\n",
    "    # Train the model\n",
    "    train_losses, val_losses, val_accuracies = train_model(model, train_loader, val_loader, epochs=10, lr=0.001)\n",
    "\n",
    "    # Save the trained model\n",
    "    save_model(model)\n",
    "\n",
    "    # Plot the training and validation losses and accuracy\n",
    "    plot_metrics(train_losses, val_losses, val_accuracies)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
